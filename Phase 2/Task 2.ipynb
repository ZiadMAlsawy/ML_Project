{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tabulate\n\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\n\nfrom sklearn.metrics import accuracy_score , confusion_matrix , precision_score , recall_score , f1_score , classification_report , auc , roc_curve , ConfusionMatrixDisplay ,  roc_auc_score\nfrom sklearn.utils import resample\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LinearRegression , LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder , RobustScaler , StandardScaler\nfrom sklearn.neural_network import MLPClassifier\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD ,Adam\n\nplt.style.use(\"fivethirtyeight\")\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:22:47.733730Z","iopub.execute_input":"2024-12-08T20:22:47.734641Z","iopub.status.idle":"2024-12-08T20:22:47.748949Z","shell.execute_reply.started":"2024-12-08T20:22:47.734605Z","shell.execute_reply":"2024-12-08T20:22:47.748231Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/creditcardfraud/creditcard.csv\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# **Obtain the Data Set**","metadata":{}},{"cell_type":"code","source":"creditCard = pd.read_csv(\"/kaggle/input/creditcardfraud/creditcard.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:22:51.055202Z","iopub.execute_input":"2024-12-08T20:22:51.055548Z","iopub.status.idle":"2024-12-08T20:22:52.747265Z","shell.execute_reply.started":"2024-12-08T20:22:51.055518Z","shell.execute_reply":"2024-12-08T20:22:52.746315Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"creditCard.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:22:52.748849Z","iopub.execute_input":"2024-12-08T20:22:52.749124Z","iopub.status.idle":"2024-12-08T20:22:52.768571Z","shell.execute_reply.started":"2024-12-08T20:22:52.749099Z","shell.execute_reply":"2024-12-08T20:22:52.767717Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"creditCard.sample(25)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:22:52.769587Z","iopub.execute_input":"2024-12-08T20:22:52.769871Z","iopub.status.idle":"2024-12-08T20:22:52.810469Z","shell.execute_reply.started":"2024-12-08T20:22:52.769846Z","shell.execute_reply":"2024-12-08T20:22:52.809648Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"            Time        V1        V2        V3        V4        V5        V6  \\\n179446  124083.0 -2.080606 -2.920073  0.836205 -3.672559  1.604440  3.699491   \n284732  172721.0  1.076175 -3.116353 -2.051439 -0.953189 -1.544838 -1.124645   \n38754    39537.0 -0.172148  0.341395  0.580698 -0.204648  2.356911  4.223087   \n169743  119837.0  2.004663  0.060830 -1.620149  0.355413  0.339289 -0.670483   \n212124  138725.0 -1.254332  1.148182  0.012605  2.442406  2.594571  0.507687   \n155896  106736.0 -0.551360  1.493324  0.746882  0.793177  1.814976 -0.670263   \n103759   68780.0  0.491469 -0.917547  1.675188  3.001976 -1.464269  0.749245   \n217211  140807.0 -0.370954  0.522789  0.675353 -0.917137  1.130020 -0.684720   \n20502    31088.0  1.125036 -0.036482 -0.178659  0.082547 -0.278707 -1.180716   \n251427  155343.0  0.100963  0.455049  0.128088 -0.374821  0.883196 -0.711429   \n81598    59006.0 -1.813849  1.770760  1.102547  1.220717 -1.496543 -0.017890   \n213618  139326.0  1.895485 -2.012869 -0.610432 -1.522366 -1.630262 -0.169777   \n183814  125960.0 -0.243230  0.822744  0.011752 -0.388077  1.580375  0.555713   \n180312  124479.0  1.955381 -0.296624 -0.020297  0.616527 -0.926628 -0.837946   \n120353   75797.0  1.236205  0.301604  0.191165  0.499567 -0.145030 -0.558027   \n262635  160571.0  1.938962  0.310074 -1.460895  1.478061  0.140742 -1.910373   \n234619  148048.0 -0.912231 -0.149887  1.214324 -1.722371  0.305815 -0.551109   \n113938   73267.0 -0.440081  0.816848  0.974341 -0.057006  0.629423 -0.602512   \n202629  134420.0 -0.643575  0.658378 -0.787036 -0.297308  3.917604  3.418705   \n200066  133267.0 -0.596671  0.448163  0.660951 -1.027742  0.833578 -0.137353   \n123726   77038.0  1.465490 -0.576524 -0.297107 -0.699456 -0.559625 -0.642968   \n251803  155507.0  2.003721 -0.080453 -1.726682  0.124841  0.445987 -0.675584   \n7504     10246.0 -0.485097  0.732274  2.445124  0.821306 -0.522298  0.296969   \n72020    54532.0 -2.992691 -0.585565  1.026862  3.234422  1.463478 -0.553754   \n125294   77605.0  1.063349  0.202181  0.654447  1.125918 -0.268564 -0.165288   \n\n              V7        V8        V9  ...       V21       V22       V23  \\\n179446 -1.557915  1.329677 -1.760050  ...  0.314032  0.347930  0.584926   \n284732  0.385570 -0.698014 -1.829401  ...  0.104853 -0.598243 -0.343164   \n38754  -0.045608  0.897343  0.338123  ... -0.146037 -0.099979 -0.308039   \n169743  0.069125 -0.080676  0.281039  ... -0.300814 -0.834183  0.348940   \n212124  1.731575 -0.426469 -1.605617  ... -0.146922  0.050381 -0.129169   \n155896  2.514047 -1.771406  2.122837  ... -0.411260  0.634144 -0.426238   \n103759 -0.702555  0.384311  0.512069  ...  0.370712  0.607597 -0.221228   \n217211  1.052606 -0.257544 -0.246461  ...  0.329245  1.070658 -0.468978   \n20502   0.459184 -0.304386 -0.485310  ...  0.065345  0.029189 -0.141477   \n251427  0.672051 -0.099717 -0.449380  ... -0.119987 -0.332765  0.135141   \n81598  -0.788896  1.364036 -0.366967  ...  0.375482  1.071997 -0.031595   \n213618 -1.225222 -0.028873 -1.278361  ... -0.257974 -0.671735  0.261758   \n183814  0.994751  0.137616 -0.234330  ...  0.247881  0.853228 -0.489669   \n180312 -0.517973 -0.155499  1.268863  ...  0.231841  0.992383  0.162081   \n120353 -0.016187 -0.041416 -0.219823  ... -0.256227 -0.769845  0.074955   \n262635  0.883682 -0.586415 -0.240304  ...  0.206033  0.649966  0.072883   \n234619 -0.171031  0.150375 -1.295853  ...  0.320996  0.686513 -0.413722   \n113938  1.776811 -0.488091 -0.596009  ...  0.072660  0.232007 -0.080660   \n202629  1.176436  0.505332 -1.411312  ...  0.126005  0.285954 -0.472205   \n200066  1.098785 -0.066044 -0.097661  ...  0.023513 -0.044721 -0.158876   \n123726 -0.365565 -0.171132 -0.506685  ...  0.086002  0.225023 -0.260556   \n251803  0.324524 -0.188161  0.397212  ...  0.165878  0.554141  0.038060   \n7504   -0.147646  0.237049  1.532716  ... -0.083815  0.063102 -0.127324   \n72020   0.141644  0.261878 -2.073118  ... -0.228843  0.393158  1.406668   \n125294 -0.022390  0.103224 -0.308511  ... -0.210191 -0.699916  0.182647   \n\n             V24       V25       V26       V27       V28  Amount  Class  \n179446  0.640121  0.574636 -0.046452  0.201931  0.171541  272.65      0  \n284732  0.088299 -0.267658 -0.313651 -0.132091  0.056029  664.60      0  \n38754   1.017950  0.383556 -0.340399 -0.079871 -0.198726    9.00      0  \n169743  0.659244 -0.329375  0.143142 -0.070244 -0.038328    8.99      0  \n212124 -0.306776  0.416783 -0.024486 -0.197810  0.105781   37.07      0  \n155896 -0.049774  0.018470 -0.596653 -0.544272 -0.840479    4.46      0  \n103759  0.405781  0.080558  0.148798  0.022320  0.086863  281.47      0  \n217211 -0.377676  0.169085 -0.152158 -0.057305 -0.094756    1.00      0  \n20502   0.631739  0.478797  1.031595 -0.128429 -0.003767   79.90      0  \n251427 -0.322723 -0.904309  0.141380  0.067550  0.093148    1.29      0  \n81598   0.671421 -0.103343 -0.194360 -0.150867 -0.003130   34.12      0  \n213618 -0.447990 -0.664700 -0.497566  0.006133 -0.017455  189.62      0  \n183814 -0.339450  0.213563 -0.539994  0.173161  0.166030    1.50      0  \n180312  0.516019 -0.113068 -0.244650  0.050694 -0.030388    4.99      0  \n120353 -0.034188  0.233108  0.096958 -0.026706  0.017564    1.98      0  \n262635  0.877215  0.334206 -0.539893 -0.032630 -0.049170   36.00      0  \n234619 -0.436430  0.689452  0.048443  0.026201  0.085859   39.99      0  \n113938 -0.123019  0.075549 -0.584017 -0.072237 -0.073292  104.66      0  \n202629  0.711675  1.160654 -0.189263 -0.143385 -0.172154   49.99      0  \n200066 -1.053086  0.088661  0.195696  0.040492  0.125234   79.95      0  \n123726 -0.425714  0.854039 -0.010130 -0.020589 -0.005661   20.00      0  \n251803  0.708606  0.327786 -0.569614 -0.018588 -0.060189   20.00      0  \n7504    0.251827 -0.108216 -0.515142 -0.068554  0.021281   12.99      0  \n72020   0.051966  0.837590  0.375254  0.222812 -0.353698   25.10      0  \n125294  0.160213  0.134554 -0.716227  0.032340  0.025923   33.48      0  \n\n[25 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>179446</th>\n      <td>124083.0</td>\n      <td>-2.080606</td>\n      <td>-2.920073</td>\n      <td>0.836205</td>\n      <td>-3.672559</td>\n      <td>1.604440</td>\n      <td>3.699491</td>\n      <td>-1.557915</td>\n      <td>1.329677</td>\n      <td>-1.760050</td>\n      <td>...</td>\n      <td>0.314032</td>\n      <td>0.347930</td>\n      <td>0.584926</td>\n      <td>0.640121</td>\n      <td>0.574636</td>\n      <td>-0.046452</td>\n      <td>0.201931</td>\n      <td>0.171541</td>\n      <td>272.65</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284732</th>\n      <td>172721.0</td>\n      <td>1.076175</td>\n      <td>-3.116353</td>\n      <td>-2.051439</td>\n      <td>-0.953189</td>\n      <td>-1.544838</td>\n      <td>-1.124645</td>\n      <td>0.385570</td>\n      <td>-0.698014</td>\n      <td>-1.829401</td>\n      <td>...</td>\n      <td>0.104853</td>\n      <td>-0.598243</td>\n      <td>-0.343164</td>\n      <td>0.088299</td>\n      <td>-0.267658</td>\n      <td>-0.313651</td>\n      <td>-0.132091</td>\n      <td>0.056029</td>\n      <td>664.60</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38754</th>\n      <td>39537.0</td>\n      <td>-0.172148</td>\n      <td>0.341395</td>\n      <td>0.580698</td>\n      <td>-0.204648</td>\n      <td>2.356911</td>\n      <td>4.223087</td>\n      <td>-0.045608</td>\n      <td>0.897343</td>\n      <td>0.338123</td>\n      <td>...</td>\n      <td>-0.146037</td>\n      <td>-0.099979</td>\n      <td>-0.308039</td>\n      <td>1.017950</td>\n      <td>0.383556</td>\n      <td>-0.340399</td>\n      <td>-0.079871</td>\n      <td>-0.198726</td>\n      <td>9.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>169743</th>\n      <td>119837.0</td>\n      <td>2.004663</td>\n      <td>0.060830</td>\n      <td>-1.620149</td>\n      <td>0.355413</td>\n      <td>0.339289</td>\n      <td>-0.670483</td>\n      <td>0.069125</td>\n      <td>-0.080676</td>\n      <td>0.281039</td>\n      <td>...</td>\n      <td>-0.300814</td>\n      <td>-0.834183</td>\n      <td>0.348940</td>\n      <td>0.659244</td>\n      <td>-0.329375</td>\n      <td>0.143142</td>\n      <td>-0.070244</td>\n      <td>-0.038328</td>\n      <td>8.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>212124</th>\n      <td>138725.0</td>\n      <td>-1.254332</td>\n      <td>1.148182</td>\n      <td>0.012605</td>\n      <td>2.442406</td>\n      <td>2.594571</td>\n      <td>0.507687</td>\n      <td>1.731575</td>\n      <td>-0.426469</td>\n      <td>-1.605617</td>\n      <td>...</td>\n      <td>-0.146922</td>\n      <td>0.050381</td>\n      <td>-0.129169</td>\n      <td>-0.306776</td>\n      <td>0.416783</td>\n      <td>-0.024486</td>\n      <td>-0.197810</td>\n      <td>0.105781</td>\n      <td>37.07</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>155896</th>\n      <td>106736.0</td>\n      <td>-0.551360</td>\n      <td>1.493324</td>\n      <td>0.746882</td>\n      <td>0.793177</td>\n      <td>1.814976</td>\n      <td>-0.670263</td>\n      <td>2.514047</td>\n      <td>-1.771406</td>\n      <td>2.122837</td>\n      <td>...</td>\n      <td>-0.411260</td>\n      <td>0.634144</td>\n      <td>-0.426238</td>\n      <td>-0.049774</td>\n      <td>0.018470</td>\n      <td>-0.596653</td>\n      <td>-0.544272</td>\n      <td>-0.840479</td>\n      <td>4.46</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>103759</th>\n      <td>68780.0</td>\n      <td>0.491469</td>\n      <td>-0.917547</td>\n      <td>1.675188</td>\n      <td>3.001976</td>\n      <td>-1.464269</td>\n      <td>0.749245</td>\n      <td>-0.702555</td>\n      <td>0.384311</td>\n      <td>0.512069</td>\n      <td>...</td>\n      <td>0.370712</td>\n      <td>0.607597</td>\n      <td>-0.221228</td>\n      <td>0.405781</td>\n      <td>0.080558</td>\n      <td>0.148798</td>\n      <td>0.022320</td>\n      <td>0.086863</td>\n      <td>281.47</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>217211</th>\n      <td>140807.0</td>\n      <td>-0.370954</td>\n      <td>0.522789</td>\n      <td>0.675353</td>\n      <td>-0.917137</td>\n      <td>1.130020</td>\n      <td>-0.684720</td>\n      <td>1.052606</td>\n      <td>-0.257544</td>\n      <td>-0.246461</td>\n      <td>...</td>\n      <td>0.329245</td>\n      <td>1.070658</td>\n      <td>-0.468978</td>\n      <td>-0.377676</td>\n      <td>0.169085</td>\n      <td>-0.152158</td>\n      <td>-0.057305</td>\n      <td>-0.094756</td>\n      <td>1.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20502</th>\n      <td>31088.0</td>\n      <td>1.125036</td>\n      <td>-0.036482</td>\n      <td>-0.178659</td>\n      <td>0.082547</td>\n      <td>-0.278707</td>\n      <td>-1.180716</td>\n      <td>0.459184</td>\n      <td>-0.304386</td>\n      <td>-0.485310</td>\n      <td>...</td>\n      <td>0.065345</td>\n      <td>0.029189</td>\n      <td>-0.141477</td>\n      <td>0.631739</td>\n      <td>0.478797</td>\n      <td>1.031595</td>\n      <td>-0.128429</td>\n      <td>-0.003767</td>\n      <td>79.90</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>251427</th>\n      <td>155343.0</td>\n      <td>0.100963</td>\n      <td>0.455049</td>\n      <td>0.128088</td>\n      <td>-0.374821</td>\n      <td>0.883196</td>\n      <td>-0.711429</td>\n      <td>0.672051</td>\n      <td>-0.099717</td>\n      <td>-0.449380</td>\n      <td>...</td>\n      <td>-0.119987</td>\n      <td>-0.332765</td>\n      <td>0.135141</td>\n      <td>-0.322723</td>\n      <td>-0.904309</td>\n      <td>0.141380</td>\n      <td>0.067550</td>\n      <td>0.093148</td>\n      <td>1.29</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>81598</th>\n      <td>59006.0</td>\n      <td>-1.813849</td>\n      <td>1.770760</td>\n      <td>1.102547</td>\n      <td>1.220717</td>\n      <td>-1.496543</td>\n      <td>-0.017890</td>\n      <td>-0.788896</td>\n      <td>1.364036</td>\n      <td>-0.366967</td>\n      <td>...</td>\n      <td>0.375482</td>\n      <td>1.071997</td>\n      <td>-0.031595</td>\n      <td>0.671421</td>\n      <td>-0.103343</td>\n      <td>-0.194360</td>\n      <td>-0.150867</td>\n      <td>-0.003130</td>\n      <td>34.12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>213618</th>\n      <td>139326.0</td>\n      <td>1.895485</td>\n      <td>-2.012869</td>\n      <td>-0.610432</td>\n      <td>-1.522366</td>\n      <td>-1.630262</td>\n      <td>-0.169777</td>\n      <td>-1.225222</td>\n      <td>-0.028873</td>\n      <td>-1.278361</td>\n      <td>...</td>\n      <td>-0.257974</td>\n      <td>-0.671735</td>\n      <td>0.261758</td>\n      <td>-0.447990</td>\n      <td>-0.664700</td>\n      <td>-0.497566</td>\n      <td>0.006133</td>\n      <td>-0.017455</td>\n      <td>189.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>183814</th>\n      <td>125960.0</td>\n      <td>-0.243230</td>\n      <td>0.822744</td>\n      <td>0.011752</td>\n      <td>-0.388077</td>\n      <td>1.580375</td>\n      <td>0.555713</td>\n      <td>0.994751</td>\n      <td>0.137616</td>\n      <td>-0.234330</td>\n      <td>...</td>\n      <td>0.247881</td>\n      <td>0.853228</td>\n      <td>-0.489669</td>\n      <td>-0.339450</td>\n      <td>0.213563</td>\n      <td>-0.539994</td>\n      <td>0.173161</td>\n      <td>0.166030</td>\n      <td>1.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>180312</th>\n      <td>124479.0</td>\n      <td>1.955381</td>\n      <td>-0.296624</td>\n      <td>-0.020297</td>\n      <td>0.616527</td>\n      <td>-0.926628</td>\n      <td>-0.837946</td>\n      <td>-0.517973</td>\n      <td>-0.155499</td>\n      <td>1.268863</td>\n      <td>...</td>\n      <td>0.231841</td>\n      <td>0.992383</td>\n      <td>0.162081</td>\n      <td>0.516019</td>\n      <td>-0.113068</td>\n      <td>-0.244650</td>\n      <td>0.050694</td>\n      <td>-0.030388</td>\n      <td>4.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>120353</th>\n      <td>75797.0</td>\n      <td>1.236205</td>\n      <td>0.301604</td>\n      <td>0.191165</td>\n      <td>0.499567</td>\n      <td>-0.145030</td>\n      <td>-0.558027</td>\n      <td>-0.016187</td>\n      <td>-0.041416</td>\n      <td>-0.219823</td>\n      <td>...</td>\n      <td>-0.256227</td>\n      <td>-0.769845</td>\n      <td>0.074955</td>\n      <td>-0.034188</td>\n      <td>0.233108</td>\n      <td>0.096958</td>\n      <td>-0.026706</td>\n      <td>0.017564</td>\n      <td>1.98</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>262635</th>\n      <td>160571.0</td>\n      <td>1.938962</td>\n      <td>0.310074</td>\n      <td>-1.460895</td>\n      <td>1.478061</td>\n      <td>0.140742</td>\n      <td>-1.910373</td>\n      <td>0.883682</td>\n      <td>-0.586415</td>\n      <td>-0.240304</td>\n      <td>...</td>\n      <td>0.206033</td>\n      <td>0.649966</td>\n      <td>0.072883</td>\n      <td>0.877215</td>\n      <td>0.334206</td>\n      <td>-0.539893</td>\n      <td>-0.032630</td>\n      <td>-0.049170</td>\n      <td>36.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>234619</th>\n      <td>148048.0</td>\n      <td>-0.912231</td>\n      <td>-0.149887</td>\n      <td>1.214324</td>\n      <td>-1.722371</td>\n      <td>0.305815</td>\n      <td>-0.551109</td>\n      <td>-0.171031</td>\n      <td>0.150375</td>\n      <td>-1.295853</td>\n      <td>...</td>\n      <td>0.320996</td>\n      <td>0.686513</td>\n      <td>-0.413722</td>\n      <td>-0.436430</td>\n      <td>0.689452</td>\n      <td>0.048443</td>\n      <td>0.026201</td>\n      <td>0.085859</td>\n      <td>39.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>113938</th>\n      <td>73267.0</td>\n      <td>-0.440081</td>\n      <td>0.816848</td>\n      <td>0.974341</td>\n      <td>-0.057006</td>\n      <td>0.629423</td>\n      <td>-0.602512</td>\n      <td>1.776811</td>\n      <td>-0.488091</td>\n      <td>-0.596009</td>\n      <td>...</td>\n      <td>0.072660</td>\n      <td>0.232007</td>\n      <td>-0.080660</td>\n      <td>-0.123019</td>\n      <td>0.075549</td>\n      <td>-0.584017</td>\n      <td>-0.072237</td>\n      <td>-0.073292</td>\n      <td>104.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>202629</th>\n      <td>134420.0</td>\n      <td>-0.643575</td>\n      <td>0.658378</td>\n      <td>-0.787036</td>\n      <td>-0.297308</td>\n      <td>3.917604</td>\n      <td>3.418705</td>\n      <td>1.176436</td>\n      <td>0.505332</td>\n      <td>-1.411312</td>\n      <td>...</td>\n      <td>0.126005</td>\n      <td>0.285954</td>\n      <td>-0.472205</td>\n      <td>0.711675</td>\n      <td>1.160654</td>\n      <td>-0.189263</td>\n      <td>-0.143385</td>\n      <td>-0.172154</td>\n      <td>49.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>200066</th>\n      <td>133267.0</td>\n      <td>-0.596671</td>\n      <td>0.448163</td>\n      <td>0.660951</td>\n      <td>-1.027742</td>\n      <td>0.833578</td>\n      <td>-0.137353</td>\n      <td>1.098785</td>\n      <td>-0.066044</td>\n      <td>-0.097661</td>\n      <td>...</td>\n      <td>0.023513</td>\n      <td>-0.044721</td>\n      <td>-0.158876</td>\n      <td>-1.053086</td>\n      <td>0.088661</td>\n      <td>0.195696</td>\n      <td>0.040492</td>\n      <td>0.125234</td>\n      <td>79.95</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>123726</th>\n      <td>77038.0</td>\n      <td>1.465490</td>\n      <td>-0.576524</td>\n      <td>-0.297107</td>\n      <td>-0.699456</td>\n      <td>-0.559625</td>\n      <td>-0.642968</td>\n      <td>-0.365565</td>\n      <td>-0.171132</td>\n      <td>-0.506685</td>\n      <td>...</td>\n      <td>0.086002</td>\n      <td>0.225023</td>\n      <td>-0.260556</td>\n      <td>-0.425714</td>\n      <td>0.854039</td>\n      <td>-0.010130</td>\n      <td>-0.020589</td>\n      <td>-0.005661</td>\n      <td>20.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>251803</th>\n      <td>155507.0</td>\n      <td>2.003721</td>\n      <td>-0.080453</td>\n      <td>-1.726682</td>\n      <td>0.124841</td>\n      <td>0.445987</td>\n      <td>-0.675584</td>\n      <td>0.324524</td>\n      <td>-0.188161</td>\n      <td>0.397212</td>\n      <td>...</td>\n      <td>0.165878</td>\n      <td>0.554141</td>\n      <td>0.038060</td>\n      <td>0.708606</td>\n      <td>0.327786</td>\n      <td>-0.569614</td>\n      <td>-0.018588</td>\n      <td>-0.060189</td>\n      <td>20.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7504</th>\n      <td>10246.0</td>\n      <td>-0.485097</td>\n      <td>0.732274</td>\n      <td>2.445124</td>\n      <td>0.821306</td>\n      <td>-0.522298</td>\n      <td>0.296969</td>\n      <td>-0.147646</td>\n      <td>0.237049</td>\n      <td>1.532716</td>\n      <td>...</td>\n      <td>-0.083815</td>\n      <td>0.063102</td>\n      <td>-0.127324</td>\n      <td>0.251827</td>\n      <td>-0.108216</td>\n      <td>-0.515142</td>\n      <td>-0.068554</td>\n      <td>0.021281</td>\n      <td>12.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>72020</th>\n      <td>54532.0</td>\n      <td>-2.992691</td>\n      <td>-0.585565</td>\n      <td>1.026862</td>\n      <td>3.234422</td>\n      <td>1.463478</td>\n      <td>-0.553754</td>\n      <td>0.141644</td>\n      <td>0.261878</td>\n      <td>-2.073118</td>\n      <td>...</td>\n      <td>-0.228843</td>\n      <td>0.393158</td>\n      <td>1.406668</td>\n      <td>0.051966</td>\n      <td>0.837590</td>\n      <td>0.375254</td>\n      <td>0.222812</td>\n      <td>-0.353698</td>\n      <td>25.10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>125294</th>\n      <td>77605.0</td>\n      <td>1.063349</td>\n      <td>0.202181</td>\n      <td>0.654447</td>\n      <td>1.125918</td>\n      <td>-0.268564</td>\n      <td>-0.165288</td>\n      <td>-0.022390</td>\n      <td>0.103224</td>\n      <td>-0.308511</td>\n      <td>...</td>\n      <td>-0.210191</td>\n      <td>-0.699916</td>\n      <td>0.182647</td>\n      <td>0.160213</td>\n      <td>0.134554</td>\n      <td>-0.716227</td>\n      <td>0.032340</td>\n      <td>0.025923</td>\n      <td>33.48</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25 rows × 31 columns</p>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"# **Exploring the Data Set**","metadata":{}},{"cell_type":"code","source":"creditCard.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:22:52.811795Z","iopub.execute_input":"2024-12-08T20:22:52.812069Z","iopub.status.idle":"2024-12-08T20:22:53.153998Z","shell.execute_reply.started":"2024-12-08T20:22:52.812044Z","shell.execute_reply":"2024-12-08T20:22:53.153135Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"           count          mean           std         min           25%  \\\nTime    284807.0  9.481386e+04  47488.145955    0.000000  54201.500000   \nV1      284807.0  1.168375e-15      1.958696  -56.407510     -0.920373   \nV2      284807.0  3.416908e-16      1.651309  -72.715728     -0.598550   \nV3      284807.0 -1.379537e-15      1.516255  -48.325589     -0.890365   \nV4      284807.0  2.074095e-15      1.415869   -5.683171     -0.848640   \nV5      284807.0  9.604066e-16      1.380247 -113.743307     -0.691597   \nV6      284807.0  1.487313e-15      1.332271  -26.160506     -0.768296   \nV7      284807.0 -5.556467e-16      1.237094  -43.557242     -0.554076   \nV8      284807.0  1.213481e-16      1.194353  -73.216718     -0.208630   \nV9      284807.0 -2.406331e-15      1.098632  -13.434066     -0.643098   \nV10     284807.0  2.239053e-15      1.088850  -24.588262     -0.535426   \nV11     284807.0  1.673327e-15      1.020713   -4.797473     -0.762494   \nV12     284807.0 -1.247012e-15      0.999201  -18.683715     -0.405571   \nV13     284807.0  8.190001e-16      0.995274   -5.791881     -0.648539   \nV14     284807.0  1.207294e-15      0.958596  -19.214325     -0.425574   \nV15     284807.0  4.887456e-15      0.915316   -4.498945     -0.582884   \nV16     284807.0  1.437716e-15      0.876253  -14.129855     -0.468037   \nV17     284807.0 -3.772171e-16      0.849337  -25.162799     -0.483748   \nV18     284807.0  9.564149e-16      0.838176   -9.498746     -0.498850   \nV19     284807.0  1.039917e-15      0.814041   -7.213527     -0.456299   \nV20     284807.0  6.406204e-16      0.770925  -54.497720     -0.211721   \nV21     284807.0  1.654067e-16      0.734524  -34.830382     -0.228395   \nV22     284807.0 -3.568593e-16      0.725702  -10.933144     -0.542350   \nV23     284807.0  2.578648e-16      0.624460  -44.807735     -0.161846   \nV24     284807.0  4.473266e-15      0.605647   -2.836627     -0.354586   \nV25     284807.0  5.340915e-16      0.521278  -10.295397     -0.317145   \nV26     284807.0  1.683437e-15      0.482227   -2.604551     -0.326984   \nV27     284807.0 -3.660091e-16      0.403632  -22.565679     -0.070840   \nV28     284807.0 -1.227390e-16      0.330083  -15.430084     -0.052960   \nAmount  284807.0  8.834962e+01    250.120109    0.000000      5.600000   \nClass   284807.0  1.727486e-03      0.041527    0.000000      0.000000   \n\n                 50%            75%            max  \nTime    84692.000000  139320.500000  172792.000000  \nV1          0.018109       1.315642       2.454930  \nV2          0.065486       0.803724      22.057729  \nV3          0.179846       1.027196       9.382558  \nV4         -0.019847       0.743341      16.875344  \nV5         -0.054336       0.611926      34.801666  \nV6         -0.274187       0.398565      73.301626  \nV7          0.040103       0.570436     120.589494  \nV8          0.022358       0.327346      20.007208  \nV9         -0.051429       0.597139      15.594995  \nV10        -0.092917       0.453923      23.745136  \nV11        -0.032757       0.739593      12.018913  \nV12         0.140033       0.618238       7.848392  \nV13        -0.013568       0.662505       7.126883  \nV14         0.050601       0.493150      10.526766  \nV15         0.048072       0.648821       8.877742  \nV16         0.066413       0.523296      17.315112  \nV17        -0.065676       0.399675       9.253526  \nV18        -0.003636       0.500807       5.041069  \nV19         0.003735       0.458949       5.591971  \nV20        -0.062481       0.133041      39.420904  \nV21        -0.029450       0.186377      27.202839  \nV22         0.006782       0.528554      10.503090  \nV23        -0.011193       0.147642      22.528412  \nV24         0.040976       0.439527       4.584549  \nV25         0.016594       0.350716       7.519589  \nV26        -0.052139       0.240952       3.517346  \nV27         0.001342       0.091045      31.612198  \nV28         0.011244       0.078280      33.847808  \nAmount     22.000000      77.165000   25691.160000  \nClass       0.000000       0.000000       1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Time</th>\n      <td>284807.0</td>\n      <td>9.481386e+04</td>\n      <td>47488.145955</td>\n      <td>0.000000</td>\n      <td>54201.500000</td>\n      <td>84692.000000</td>\n      <td>139320.500000</td>\n      <td>172792.000000</td>\n    </tr>\n    <tr>\n      <th>V1</th>\n      <td>284807.0</td>\n      <td>1.168375e-15</td>\n      <td>1.958696</td>\n      <td>-56.407510</td>\n      <td>-0.920373</td>\n      <td>0.018109</td>\n      <td>1.315642</td>\n      <td>2.454930</td>\n    </tr>\n    <tr>\n      <th>V2</th>\n      <td>284807.0</td>\n      <td>3.416908e-16</td>\n      <td>1.651309</td>\n      <td>-72.715728</td>\n      <td>-0.598550</td>\n      <td>0.065486</td>\n      <td>0.803724</td>\n      <td>22.057729</td>\n    </tr>\n    <tr>\n      <th>V3</th>\n      <td>284807.0</td>\n      <td>-1.379537e-15</td>\n      <td>1.516255</td>\n      <td>-48.325589</td>\n      <td>-0.890365</td>\n      <td>0.179846</td>\n      <td>1.027196</td>\n      <td>9.382558</td>\n    </tr>\n    <tr>\n      <th>V4</th>\n      <td>284807.0</td>\n      <td>2.074095e-15</td>\n      <td>1.415869</td>\n      <td>-5.683171</td>\n      <td>-0.848640</td>\n      <td>-0.019847</td>\n      <td>0.743341</td>\n      <td>16.875344</td>\n    </tr>\n    <tr>\n      <th>V5</th>\n      <td>284807.0</td>\n      <td>9.604066e-16</td>\n      <td>1.380247</td>\n      <td>-113.743307</td>\n      <td>-0.691597</td>\n      <td>-0.054336</td>\n      <td>0.611926</td>\n      <td>34.801666</td>\n    </tr>\n    <tr>\n      <th>V6</th>\n      <td>284807.0</td>\n      <td>1.487313e-15</td>\n      <td>1.332271</td>\n      <td>-26.160506</td>\n      <td>-0.768296</td>\n      <td>-0.274187</td>\n      <td>0.398565</td>\n      <td>73.301626</td>\n    </tr>\n    <tr>\n      <th>V7</th>\n      <td>284807.0</td>\n      <td>-5.556467e-16</td>\n      <td>1.237094</td>\n      <td>-43.557242</td>\n      <td>-0.554076</td>\n      <td>0.040103</td>\n      <td>0.570436</td>\n      <td>120.589494</td>\n    </tr>\n    <tr>\n      <th>V8</th>\n      <td>284807.0</td>\n      <td>1.213481e-16</td>\n      <td>1.194353</td>\n      <td>-73.216718</td>\n      <td>-0.208630</td>\n      <td>0.022358</td>\n      <td>0.327346</td>\n      <td>20.007208</td>\n    </tr>\n    <tr>\n      <th>V9</th>\n      <td>284807.0</td>\n      <td>-2.406331e-15</td>\n      <td>1.098632</td>\n      <td>-13.434066</td>\n      <td>-0.643098</td>\n      <td>-0.051429</td>\n      <td>0.597139</td>\n      <td>15.594995</td>\n    </tr>\n    <tr>\n      <th>V10</th>\n      <td>284807.0</td>\n      <td>2.239053e-15</td>\n      <td>1.088850</td>\n      <td>-24.588262</td>\n      <td>-0.535426</td>\n      <td>-0.092917</td>\n      <td>0.453923</td>\n      <td>23.745136</td>\n    </tr>\n    <tr>\n      <th>V11</th>\n      <td>284807.0</td>\n      <td>1.673327e-15</td>\n      <td>1.020713</td>\n      <td>-4.797473</td>\n      <td>-0.762494</td>\n      <td>-0.032757</td>\n      <td>0.739593</td>\n      <td>12.018913</td>\n    </tr>\n    <tr>\n      <th>V12</th>\n      <td>284807.0</td>\n      <td>-1.247012e-15</td>\n      <td>0.999201</td>\n      <td>-18.683715</td>\n      <td>-0.405571</td>\n      <td>0.140033</td>\n      <td>0.618238</td>\n      <td>7.848392</td>\n    </tr>\n    <tr>\n      <th>V13</th>\n      <td>284807.0</td>\n      <td>8.190001e-16</td>\n      <td>0.995274</td>\n      <td>-5.791881</td>\n      <td>-0.648539</td>\n      <td>-0.013568</td>\n      <td>0.662505</td>\n      <td>7.126883</td>\n    </tr>\n    <tr>\n      <th>V14</th>\n      <td>284807.0</td>\n      <td>1.207294e-15</td>\n      <td>0.958596</td>\n      <td>-19.214325</td>\n      <td>-0.425574</td>\n      <td>0.050601</td>\n      <td>0.493150</td>\n      <td>10.526766</td>\n    </tr>\n    <tr>\n      <th>V15</th>\n      <td>284807.0</td>\n      <td>4.887456e-15</td>\n      <td>0.915316</td>\n      <td>-4.498945</td>\n      <td>-0.582884</td>\n      <td>0.048072</td>\n      <td>0.648821</td>\n      <td>8.877742</td>\n    </tr>\n    <tr>\n      <th>V16</th>\n      <td>284807.0</td>\n      <td>1.437716e-15</td>\n      <td>0.876253</td>\n      <td>-14.129855</td>\n      <td>-0.468037</td>\n      <td>0.066413</td>\n      <td>0.523296</td>\n      <td>17.315112</td>\n    </tr>\n    <tr>\n      <th>V17</th>\n      <td>284807.0</td>\n      <td>-3.772171e-16</td>\n      <td>0.849337</td>\n      <td>-25.162799</td>\n      <td>-0.483748</td>\n      <td>-0.065676</td>\n      <td>0.399675</td>\n      <td>9.253526</td>\n    </tr>\n    <tr>\n      <th>V18</th>\n      <td>284807.0</td>\n      <td>9.564149e-16</td>\n      <td>0.838176</td>\n      <td>-9.498746</td>\n      <td>-0.498850</td>\n      <td>-0.003636</td>\n      <td>0.500807</td>\n      <td>5.041069</td>\n    </tr>\n    <tr>\n      <th>V19</th>\n      <td>284807.0</td>\n      <td>1.039917e-15</td>\n      <td>0.814041</td>\n      <td>-7.213527</td>\n      <td>-0.456299</td>\n      <td>0.003735</td>\n      <td>0.458949</td>\n      <td>5.591971</td>\n    </tr>\n    <tr>\n      <th>V20</th>\n      <td>284807.0</td>\n      <td>6.406204e-16</td>\n      <td>0.770925</td>\n      <td>-54.497720</td>\n      <td>-0.211721</td>\n      <td>-0.062481</td>\n      <td>0.133041</td>\n      <td>39.420904</td>\n    </tr>\n    <tr>\n      <th>V21</th>\n      <td>284807.0</td>\n      <td>1.654067e-16</td>\n      <td>0.734524</td>\n      <td>-34.830382</td>\n      <td>-0.228395</td>\n      <td>-0.029450</td>\n      <td>0.186377</td>\n      <td>27.202839</td>\n    </tr>\n    <tr>\n      <th>V22</th>\n      <td>284807.0</td>\n      <td>-3.568593e-16</td>\n      <td>0.725702</td>\n      <td>-10.933144</td>\n      <td>-0.542350</td>\n      <td>0.006782</td>\n      <td>0.528554</td>\n      <td>10.503090</td>\n    </tr>\n    <tr>\n      <th>V23</th>\n      <td>284807.0</td>\n      <td>2.578648e-16</td>\n      <td>0.624460</td>\n      <td>-44.807735</td>\n      <td>-0.161846</td>\n      <td>-0.011193</td>\n      <td>0.147642</td>\n      <td>22.528412</td>\n    </tr>\n    <tr>\n      <th>V24</th>\n      <td>284807.0</td>\n      <td>4.473266e-15</td>\n      <td>0.605647</td>\n      <td>-2.836627</td>\n      <td>-0.354586</td>\n      <td>0.040976</td>\n      <td>0.439527</td>\n      <td>4.584549</td>\n    </tr>\n    <tr>\n      <th>V25</th>\n      <td>284807.0</td>\n      <td>5.340915e-16</td>\n      <td>0.521278</td>\n      <td>-10.295397</td>\n      <td>-0.317145</td>\n      <td>0.016594</td>\n      <td>0.350716</td>\n      <td>7.519589</td>\n    </tr>\n    <tr>\n      <th>V26</th>\n      <td>284807.0</td>\n      <td>1.683437e-15</td>\n      <td>0.482227</td>\n      <td>-2.604551</td>\n      <td>-0.326984</td>\n      <td>-0.052139</td>\n      <td>0.240952</td>\n      <td>3.517346</td>\n    </tr>\n    <tr>\n      <th>V27</th>\n      <td>284807.0</td>\n      <td>-3.660091e-16</td>\n      <td>0.403632</td>\n      <td>-22.565679</td>\n      <td>-0.070840</td>\n      <td>0.001342</td>\n      <td>0.091045</td>\n      <td>31.612198</td>\n    </tr>\n    <tr>\n      <th>V28</th>\n      <td>284807.0</td>\n      <td>-1.227390e-16</td>\n      <td>0.330083</td>\n      <td>-15.430084</td>\n      <td>-0.052960</td>\n      <td>0.011244</td>\n      <td>0.078280</td>\n      <td>33.847808</td>\n    </tr>\n    <tr>\n      <th>Amount</th>\n      <td>284807.0</td>\n      <td>8.834962e+01</td>\n      <td>250.120109</td>\n      <td>0.000000</td>\n      <td>5.600000</td>\n      <td>22.000000</td>\n      <td>77.165000</td>\n      <td>25691.160000</td>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <td>284807.0</td>\n      <td>1.727486e-03</td>\n      <td>0.041527</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"creditCard.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:22:53.155430Z","iopub.execute_input":"2024-12-08T20:22:53.156132Z","iopub.status.idle":"2024-12-08T20:22:53.178012Z","shell.execute_reply.started":"2024-12-08T20:22:53.156093Z","shell.execute_reply":"2024-12-08T20:22:53.177231Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 284807 entries, 0 to 284806\nData columns (total 31 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   Time    284807 non-null  float64\n 1   V1      284807 non-null  float64\n 2   V2      284807 non-null  float64\n 3   V3      284807 non-null  float64\n 4   V4      284807 non-null  float64\n 5   V5      284807 non-null  float64\n 6   V6      284807 non-null  float64\n 7   V7      284807 non-null  float64\n 8   V8      284807 non-null  float64\n 9   V9      284807 non-null  float64\n 10  V10     284807 non-null  float64\n 11  V11     284807 non-null  float64\n 12  V12     284807 non-null  float64\n 13  V13     284807 non-null  float64\n 14  V14     284807 non-null  float64\n 15  V15     284807 non-null  float64\n 16  V16     284807 non-null  float64\n 17  V17     284807 non-null  float64\n 18  V18     284807 non-null  float64\n 19  V19     284807 non-null  float64\n 20  V20     284807 non-null  float64\n 21  V21     284807 non-null  float64\n 22  V22     284807 non-null  float64\n 23  V23     284807 non-null  float64\n 24  V24     284807 non-null  float64\n 25  V25     284807 non-null  float64\n 26  V26     284807 non-null  float64\n 27  V27     284807 non-null  float64\n 28  V28     284807 non-null  float64\n 29  Amount  284807 non-null  float64\n 30  Class   284807 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 67.4 MB\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"print(f\"The Data Set contain {creditCard.shape[0]} Rows & {creditCard.shape[1]} Columns\")\nprint(f\"The Data Set contain {creditCard.duplicated().sum()} record duplicated\") # Flag Here\nprint(f\"Number of Nulls in each features :\\n{creditCard.isna().sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:22:53.178916Z","iopub.execute_input":"2024-12-08T20:22:53.179158Z","iopub.status.idle":"2024-12-08T20:22:53.639125Z","shell.execute_reply.started":"2024-12-08T20:22:53.179134Z","shell.execute_reply":"2024-12-08T20:22:53.638326Z"}},"outputs":[{"name":"stdout","text":"The Data Set contain 284807 Rows & 31 Columns\nThe Data Set contain 1081 record duplicated\nNumber of Nulls in each features :\nTime      0\nV1        0\nV2        0\nV3        0\nV4        0\nV5        0\nV6        0\nV7        0\nV8        0\nV9        0\nV10       0\nV11       0\nV12       0\nV13       0\nV14       0\nV15       0\nV16       0\nV17       0\nV18       0\nV19       0\nV20       0\nV21       0\nV22       0\nV23       0\nV24       0\nV25       0\nV26       0\nV27       0\nV28       0\nAmount    0\nClass     0\ndtype: int64\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"# **Imbalanced Features Resolving**","metadata":{}},{"cell_type":"code","source":"X , y = creditCard.drop('Class', axis=1) , creditCard['Class']\n\nsmote = SMOTE(random_state=42)\nX_resampled_smote, y_resampled_smote = smote.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X_resampled_smote, y_resampled_smote, test_size=0.2, random_state=42)\n\nscaler = RobustScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:22:56.443046Z","iopub.execute_input":"2024-12-08T20:22:56.443396Z","iopub.status.idle":"2024-12-08T20:22:57.756493Z","shell.execute_reply.started":"2024-12-08T20:22:56.443365Z","shell.execute_reply":"2024-12-08T20:22:57.755730Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"# **Modeling Our Data**","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))  \nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\n\nmodel.add(Dense(len(np.unique(y_train)), activation='softmax')) \n\nmodel.compile(optimizer=Adam(learning_rate=0.0005), \n              loss='sparse_categorical_crossentropy',  \n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs= 10, batch_size=32, verbose=1)\n\ny_pred_multiclass = np.argmax(model.predict(X_test), axis=1)  \n\nprint(\"Optimized Multiclass Classification Report:\")\nprint(classification_report(y_test, y_pred_multiclass))\nprint(precision_score(y_test, y_pred_multiclass))\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_multiclass)}\")\n\nmodel.evaluate(X_test,y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:23:13.313356Z","iopub.execute_input":"2024-12-08T20:23:13.313683Z","iopub.status.idle":"2024-12-08T20:26:43.910875Z","shell.execute_reply.started":"2024-12-08T20:23:13.313654Z","shell.execute_reply":"2024-12-08T20:26:43.909823Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9897 - loss: 0.0325\nEpoch 2/10\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0060\nEpoch 3/10\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0042\nEpoch 4/10\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0032\nEpoch 5/10\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0032\nEpoch 6/10\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0031\nEpoch 7/10\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0023\nEpoch 8/10\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0019\nEpoch 9/10\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0022\nEpoch 10/10\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0037\n\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))  \nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\n\nmodel.add(Dense(len(np.unique(y_train)), activation='softmax')) \n\nmodel.compile(optimizer=SGD(learning_rate=0.0005), \n              loss='sparse_categorical_crossentropy',  \n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs= 50, batch_size=32, verbose=1)\n\ny_pred_multiclass = np.argmax(model.predict(X_test), axis=1)  \n\nprint(\"Optimized Multiclass Classification Report:\")\nprint(classification_report(y_test, y_pred_multiclass))\nprint(precision_score(y_test, y_pred_multiclass))\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_multiclass)}\")\n\nmodel.evaluate(X_test,y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:26:48.373249Z","iopub.execute_input":"2024-12-08T20:26:48.373606Z","iopub.status.idle":"2024-12-08T20:27:50.025370Z","shell.execute_reply.started":"2024-12-08T20:26:48.373567Z","shell.execute_reply":"2024-12-08T20:27:50.024010Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - accuracy: 0.9086 - loss: 0.3261\nEpoch 2/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - accuracy: 0.9693 - loss: 0.0898\nEpoch 3/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - accuracy: 0.9776 - loss: 0.0647\nEpoch 4/50\n\u001b[1m 6241/14216\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.9815 - loss: 0.0547","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[38], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_train)), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)) \n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m), \n\u001b[1;32m     10\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,  \n\u001b[1;32m     11\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m y_pred_multiclass \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(model\u001b[38;5;241m.\u001b[39mpredict(X_test), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized Multiclass Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:239\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    229\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    230\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    231\u001b[0m         args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_cache.py:48\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, function_type, context)\u001b[0m\n\u001b[1;32m     46\u001b[0m context \u001b[38;5;241m=\u001b[39m context \u001b[38;5;129;01mor\u001b[39;00m FunctionContext()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict:\n\u001b[0;32m---> 48\u001b[0m   dispatch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_primary[(context, dispatch_type)]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/type_dispatch.py:80\u001b[0m, in \u001b[0;36mTypeDispatchTable.dispatch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the most specific supertype target if it exists in the table.\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# For known exact matches.\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_table\u001b[49m:\n\u001b[1;32m     81\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m request\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# For known non-exact matches.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# (self._dispatch cache does not contain exact matches)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:456\u001b[0m, in \u001b[0;36mFunctionType.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:155\u001b[0m, in \u001b[0;36mParameter.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 155\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/type_spec.py:554\u001b[0m, in \u001b[0;36mTypeSpec.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 554\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/type_spec.py:607\u001b[0m, in \u001b[0;36mTypeSpec.__get_cmp_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, _CACHED_CMP_KEY):\n\u001b[1;32m    603\u001b[0m   \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, _CACHED_CMP_KEY, (\n\u001b[1;32m    604\u001b[0m       \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    605\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialize()),\n\u001b[1;32m    606\u001b[0m   ))\n\u001b[0;32m--> 607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_CACHED_CMP_KEY\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":38}]}
