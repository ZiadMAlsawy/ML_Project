{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 23498,
          "sourceType": "datasetVersion",
          "datasetId": 310
        },
        {
          "sourceId": 10161703,
          "sourceType": "datasetVersion",
          "datasetId": 6274876
        }
      ],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "class Trace_back_epochs(Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epochs = []\n",
        "        self.loss = []\n",
        "        self.val_loss = []\n",
        "        self.accuracy = []\n",
        "        self.val_accuracy = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.epochs.append(epoch + 1)\n",
        "        self.loss.append(logs.get(\"loss\"))\n",
        "        self.val_loss.append(logs.get(\"val_loss\"))\n",
        "        self.accuracy.append(logs.get(\"accuracy\"))\n",
        "        self.val_accuracy.append(logs.get(\"val_accuracy\"))\n",
        "\n",
        "\n",
        "    def export_to_file(self, filepath):\n",
        "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
        "        with open(filepath, \"w\") as fp:\n",
        "            fp.write(\"Validation Loss:\\n\")\n",
        "            fp.writelines('%s\\n' % value for value in self.val_loss)\n",
        "            fp.write(\"\\nValidation Accuracy:\\n\")\n",
        "            fp.writelines('%s\\n' % value for value in self.val_accuracy)"
      ],
      "metadata": {
        "id": "JcDx1FvC04YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tabulate\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.metrics import accuracy_score , confusion_matrix , precision_score , recall_score , f1_score , classification_report , auc , roc_curve , ConfusionMatrixDisplay ,  roc_auc_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LinearRegression , LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder , RobustScaler , StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD ,Adam\n",
        "\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T23:27:57.330991Z",
          "iopub.execute_input": "2024-12-10T23:27:57.331383Z",
          "iopub.status.idle": "2024-12-10T23:27:57.730084Z",
          "shell.execute_reply.started": "2024-12-10T23:27:57.331350Z",
          "shell.execute_reply": "2024-12-10T23:27:57.729257Z"
        },
        "id": "QBcJ5Sk10rrF",
        "outputId": "dd775eac-554a-457d-8001-5e9ed7d4e5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/creditcardfraud/creditcard.csv\n/kaggle/input/classification-test-file/Classification_Test_file.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Obtain the Data Set**"
      ],
      "metadata": {
        "id": "-verUFZe0rrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "creditCard = pd.read_csv(\"/kaggle/input/creditcardfraud/creditcard.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T23:27:59.199974Z",
          "iopub.execute_input": "2024-12-10T23:27:59.201000Z",
          "iopub.status.idle": "2024-12-10T23:28:02.035184Z",
          "shell.execute_reply.started": "2024-12-10T23:27:59.200961Z",
          "shell.execute_reply": "2024-12-10T23:28:02.034182Z"
        },
        "id": "16qO6Isn0rrM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "creditCard.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T23:28:02.036789Z",
          "iopub.execute_input": "2024-12-10T23:28:02.037062Z",
          "iopub.status.idle": "2024-12-10T23:28:02.066808Z",
          "shell.execute_reply.started": "2024-12-10T23:28:02.037035Z",
          "shell.execute_reply": "2024-12-10T23:28:02.066106Z"
        },
        "id": "6j1Bj7Fa0rrN",
        "outputId": "49304153-1c33-4577-d4b0-125906c7ad2b"
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "creditCard.sample(25)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T23:28:02.067954Z",
          "iopub.execute_input": "2024-12-10T23:28:02.068185Z",
          "iopub.status.idle": "2024-12-10T23:28:02.105711Z",
          "shell.execute_reply.started": "2024-12-10T23:28:02.068161Z",
          "shell.execute_reply": "2024-12-10T23:28:02.104945Z"
        },
        "id": "c9eiV28U0rrO",
        "outputId": "3c1d28aa-7380-4bf0-ba8b-920be0c20ad6"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            Time         V1         V2        V3        V4        V5  \\\n109395   71364.0   1.256634   0.388227  0.315844  0.688999 -0.330299   \n74056    55405.0   1.292317   0.140220 -0.197207  0.323588  0.089596   \n122341   76524.0  -0.157467   2.158979 -4.258577  0.510864  2.809428   \n241895  151238.0  -0.650042  -0.058826  1.259346  0.297769 -0.804720   \n145412   86923.0  -0.246616   1.181016 -0.710945 -0.590141  0.552103   \n111924   72430.0  -0.987278   1.497701  0.828519  0.001885 -0.388194   \n258519  158690.0   2.085848   0.177487 -1.761855  0.377901  0.520699   \n257944  158421.0  -0.850078   0.340200  0.018070 -0.903625  1.262558   \n223201  143285.0   2.019439   0.066202 -1.789726  0.569476  0.050605   \n216609  140552.0  -2.290026  -0.772080  0.810270 -0.940607  0.700672   \n144814   86425.0   1.763241  -1.348472 -2.088271 -1.730570  1.440972   \n150166   92698.0   2.023521   0.214231 -1.464569  0.550398  0.440221   \n274927  166279.0   1.568033  -0.213043 -0.415472  4.250062 -0.135853   \n11312    19692.0   1.165889  -0.390112  0.892399 -0.754121 -0.755755   \n6285      7413.0  -1.259891  -0.726624  2.327557 -2.315130 -1.715768   \n236223  148717.0   2.338682  -1.334974 -1.378726 -1.908951 -0.550774   \n201201  133772.0   2.080428  -0.126444 -1.407207  0.351369 -0.115538   \n248330  153893.0   0.857433   0.679099 -3.725069 -1.234750  3.388773   \n284600  172590.0   2.058257  -1.714452 -1.002894 -1.557228 -1.314964   \n187686  127645.0  -0.011719   1.106394 -0.282688  0.661797  1.757857   \n249194  154288.0  -0.513755  -0.200756  1.430028 -2.203717  0.316228   \n224272  143719.0 -12.034428 -13.595066 -3.446061  1.526567  5.433066   \n32711    36934.0   1.037612  -0.092885  0.208346  1.253284 -0.063390   \n9165     13083.0  -0.197607   1.035874  1.045698 -0.190877  0.912472   \n141046   84096.0   1.240697   0.084088  0.387617  0.231309 -0.275212   \n\n              V6        V7        V8        V9  ...       V21       V22  \\\n109395 -1.062301  0.118363 -0.230313 -0.038034  ... -0.282242 -0.791741   \n74056  -0.130499 -0.160260  0.117665  0.123859  ... -0.332552 -1.078333   \n122341  2.261109 -0.370936  1.550093 -0.549905  ... -0.129517 -0.519052   \n241895  1.090243 -1.188712 -2.388140  0.770459  ... -1.464883 -0.453283   \n145412 -0.575163  0.438263  0.531144 -0.353602  ... -0.245213 -0.757593   \n111924 -0.805212  0.857727  0.024452 -0.262863  ... -0.299642 -0.654924   \n258519 -0.783871  0.204877 -0.245342  0.454810  ... -0.370981 -0.946580   \n257944  1.055225  1.040310  0.440181 -0.128618  ...  0.004852 -0.022146   \n223201 -1.491212  0.175435 -0.283645  0.826815  ...  0.185817  0.610967   \n216609  1.254000  0.040544  1.170115  0.147594  ... -0.143764 -1.041655   \n144814  3.541201 -1.078298  0.919753  1.384753  ...  0.261387  0.499989   \n150166 -0.621447 -0.020361 -0.170860  1.535655  ... -0.453848 -0.999219   \n274927  0.280004  0.126273  0.054357 -0.102412  ... -0.281574 -0.930429   \n11312   0.205039 -0.849606  0.199267  2.888464  ... -0.100379  0.175587   \n6285   -0.258039  1.413266 -0.325328  2.575683  ...  0.295721  0.648250   \n236223  0.238072 -1.158720 -0.009707 -1.507455  ... -0.176079  0.000021   \n201201 -1.324759  0.144910 -0.303543  0.857661  ...  0.217186  0.712214   \n248330  3.137934 -0.348392 -2.192127 -0.789256  ... -0.844067  1.666051   \n284600 -0.494054 -0.997273 -0.166715 -1.482291  ... -0.084824  0.014041   \n187686 -0.008939  1.482610 -0.352972 -0.451525  ...  0.009578  0.483270   \n249194 -0.211684  0.763676 -0.708394 -0.531281  ...  0.091249  0.722135   \n224272 -5.388983 -1.189171  0.376458 -1.870549  ...  0.744190  0.543820   \n32711   0.331403 -0.029316  0.189614  0.182889  ... -0.048541 -0.106970   \n9165    0.174510  0.664141 -0.115599  0.935436  ... -0.505791 -1.019145   \n141046 -0.360848 -0.052933 -0.068952  0.017515  ... -0.204751 -0.450572   \n\n             V23       V24       V25       V26       V27       V28  Amount  \\\n109395  0.123791  0.358121  0.231831  0.092843 -0.020027  0.031824    1.78   \n74056  -0.007335 -0.939655  0.280504  0.155857 -0.040197  0.004994    2.69   \n122341  0.184903  0.648820 -0.211999 -0.388844 -0.021067 -0.059967    0.79   \n241895 -0.353733  0.625838  1.325589 -0.549753  0.041847  0.223882  200.00   \n145412  0.166595  0.576772 -0.488017  0.097795  0.091399  0.010884    1.98   \n111924  0.017159  0.294652 -0.088796  0.040828 -0.029621 -0.145301   69.99   \n258519  0.316339  0.387947 -0.226184  0.180220 -0.060790 -0.031292    1.98   \n257944  0.083679 -1.562939 -0.109590  0.011221  0.104328  0.140642  128.70   \n223201 -0.008402 -0.129028  0.178851 -0.094397 -0.011067 -0.030411   17.43   \n216609  0.289068 -1.727704  0.245520 -0.170436  0.134792 -0.118533  186.48   \n144814  0.095395  0.782473 -0.352024  0.710751 -0.044774 -0.033901  148.00   \n150166  0.365368  0.603461 -0.342527  0.104715 -0.094095 -0.045708    0.89   \n274927  0.189136 -0.087845 -0.244244 -0.269846 -0.042632 -0.020087  160.41   \n11312  -0.055054 -0.349088  0.408547 -0.693195  0.076051  0.013507   11.85   \n6285    0.427393  0.331621  0.477176 -0.093332 -0.259823 -0.135088  370.39   \n236223  0.153596 -0.216030 -0.059567 -0.154875  0.006452 -0.064696    6.00   \n201201  0.000297 -0.118319  0.231340 -0.096090 -0.030888 -0.063446    3.00   \n248330  0.062654  0.792094 -0.228489  0.487223  0.235530  0.416906    1.00   \n284600  0.103746 -0.342943 -0.246576 -0.207427 -0.008154 -0.041851  126.00   \n187686 -0.382314 -0.013467  0.117852 -0.390229  0.268704  0.020517    5.15   \n249194 -0.263764 -0.397016 -0.053290 -0.297371 -0.727034 -0.622340   17.95   \n224272  1.181284  0.941908  2.147286  0.290423  0.918294 -3.529290    8.25   \n32711  -0.152946 -0.309133  0.626348 -0.312789  0.019332  0.010227   63.64   \n9165   -0.209408 -1.129660 -0.076380  0.071582  0.046155 -0.155653    5.49   \n141046 -0.002618  0.066256  0.378015  0.444868 -0.039896 -0.000662    4.00   \n\n        Class  \n109395      0  \n74056       0  \n122341      0  \n241895      0  \n145412      0  \n111924      0  \n258519      0  \n257944      0  \n223201      0  \n216609      0  \n144814      0  \n150166      0  \n274927      0  \n11312       0  \n6285        0  \n236223      0  \n201201      0  \n248330      0  \n284600      0  \n187686      0  \n249194      0  \n224272      0  \n32711       0  \n9165        0  \n141046      0  \n\n[25 rows x 31 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>109395</th>\n      <td>71364.0</td>\n      <td>1.256634</td>\n      <td>0.388227</td>\n      <td>0.315844</td>\n      <td>0.688999</td>\n      <td>-0.330299</td>\n      <td>-1.062301</td>\n      <td>0.118363</td>\n      <td>-0.230313</td>\n      <td>-0.038034</td>\n      <td>...</td>\n      <td>-0.282242</td>\n      <td>-0.791741</td>\n      <td>0.123791</td>\n      <td>0.358121</td>\n      <td>0.231831</td>\n      <td>0.092843</td>\n      <td>-0.020027</td>\n      <td>0.031824</td>\n      <td>1.78</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74056</th>\n      <td>55405.0</td>\n      <td>1.292317</td>\n      <td>0.140220</td>\n      <td>-0.197207</td>\n      <td>0.323588</td>\n      <td>0.089596</td>\n      <td>-0.130499</td>\n      <td>-0.160260</td>\n      <td>0.117665</td>\n      <td>0.123859</td>\n      <td>...</td>\n      <td>-0.332552</td>\n      <td>-1.078333</td>\n      <td>-0.007335</td>\n      <td>-0.939655</td>\n      <td>0.280504</td>\n      <td>0.155857</td>\n      <td>-0.040197</td>\n      <td>0.004994</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>122341</th>\n      <td>76524.0</td>\n      <td>-0.157467</td>\n      <td>2.158979</td>\n      <td>-4.258577</td>\n      <td>0.510864</td>\n      <td>2.809428</td>\n      <td>2.261109</td>\n      <td>-0.370936</td>\n      <td>1.550093</td>\n      <td>-0.549905</td>\n      <td>...</td>\n      <td>-0.129517</td>\n      <td>-0.519052</td>\n      <td>0.184903</td>\n      <td>0.648820</td>\n      <td>-0.211999</td>\n      <td>-0.388844</td>\n      <td>-0.021067</td>\n      <td>-0.059967</td>\n      <td>0.79</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>241895</th>\n      <td>151238.0</td>\n      <td>-0.650042</td>\n      <td>-0.058826</td>\n      <td>1.259346</td>\n      <td>0.297769</td>\n      <td>-0.804720</td>\n      <td>1.090243</td>\n      <td>-1.188712</td>\n      <td>-2.388140</td>\n      <td>0.770459</td>\n      <td>...</td>\n      <td>-1.464883</td>\n      <td>-0.453283</td>\n      <td>-0.353733</td>\n      <td>0.625838</td>\n      <td>1.325589</td>\n      <td>-0.549753</td>\n      <td>0.041847</td>\n      <td>0.223882</td>\n      <td>200.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>145412</th>\n      <td>86923.0</td>\n      <td>-0.246616</td>\n      <td>1.181016</td>\n      <td>-0.710945</td>\n      <td>-0.590141</td>\n      <td>0.552103</td>\n      <td>-0.575163</td>\n      <td>0.438263</td>\n      <td>0.531144</td>\n      <td>-0.353602</td>\n      <td>...</td>\n      <td>-0.245213</td>\n      <td>-0.757593</td>\n      <td>0.166595</td>\n      <td>0.576772</td>\n      <td>-0.488017</td>\n      <td>0.097795</td>\n      <td>0.091399</td>\n      <td>0.010884</td>\n      <td>1.98</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>111924</th>\n      <td>72430.0</td>\n      <td>-0.987278</td>\n      <td>1.497701</td>\n      <td>0.828519</td>\n      <td>0.001885</td>\n      <td>-0.388194</td>\n      <td>-0.805212</td>\n      <td>0.857727</td>\n      <td>0.024452</td>\n      <td>-0.262863</td>\n      <td>...</td>\n      <td>-0.299642</td>\n      <td>-0.654924</td>\n      <td>0.017159</td>\n      <td>0.294652</td>\n      <td>-0.088796</td>\n      <td>0.040828</td>\n      <td>-0.029621</td>\n      <td>-0.145301</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>258519</th>\n      <td>158690.0</td>\n      <td>2.085848</td>\n      <td>0.177487</td>\n      <td>-1.761855</td>\n      <td>0.377901</td>\n      <td>0.520699</td>\n      <td>-0.783871</td>\n      <td>0.204877</td>\n      <td>-0.245342</td>\n      <td>0.454810</td>\n      <td>...</td>\n      <td>-0.370981</td>\n      <td>-0.946580</td>\n      <td>0.316339</td>\n      <td>0.387947</td>\n      <td>-0.226184</td>\n      <td>0.180220</td>\n      <td>-0.060790</td>\n      <td>-0.031292</td>\n      <td>1.98</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>257944</th>\n      <td>158421.0</td>\n      <td>-0.850078</td>\n      <td>0.340200</td>\n      <td>0.018070</td>\n      <td>-0.903625</td>\n      <td>1.262558</td>\n      <td>1.055225</td>\n      <td>1.040310</td>\n      <td>0.440181</td>\n      <td>-0.128618</td>\n      <td>...</td>\n      <td>0.004852</td>\n      <td>-0.022146</td>\n      <td>0.083679</td>\n      <td>-1.562939</td>\n      <td>-0.109590</td>\n      <td>0.011221</td>\n      <td>0.104328</td>\n      <td>0.140642</td>\n      <td>128.70</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>223201</th>\n      <td>143285.0</td>\n      <td>2.019439</td>\n      <td>0.066202</td>\n      <td>-1.789726</td>\n      <td>0.569476</td>\n      <td>0.050605</td>\n      <td>-1.491212</td>\n      <td>0.175435</td>\n      <td>-0.283645</td>\n      <td>0.826815</td>\n      <td>...</td>\n      <td>0.185817</td>\n      <td>0.610967</td>\n      <td>-0.008402</td>\n      <td>-0.129028</td>\n      <td>0.178851</td>\n      <td>-0.094397</td>\n      <td>-0.011067</td>\n      <td>-0.030411</td>\n      <td>17.43</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>216609</th>\n      <td>140552.0</td>\n      <td>-2.290026</td>\n      <td>-0.772080</td>\n      <td>0.810270</td>\n      <td>-0.940607</td>\n      <td>0.700672</td>\n      <td>1.254000</td>\n      <td>0.040544</td>\n      <td>1.170115</td>\n      <td>0.147594</td>\n      <td>...</td>\n      <td>-0.143764</td>\n      <td>-1.041655</td>\n      <td>0.289068</td>\n      <td>-1.727704</td>\n      <td>0.245520</td>\n      <td>-0.170436</td>\n      <td>0.134792</td>\n      <td>-0.118533</td>\n      <td>186.48</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>144814</th>\n      <td>86425.0</td>\n      <td>1.763241</td>\n      <td>-1.348472</td>\n      <td>-2.088271</td>\n      <td>-1.730570</td>\n      <td>1.440972</td>\n      <td>3.541201</td>\n      <td>-1.078298</td>\n      <td>0.919753</td>\n      <td>1.384753</td>\n      <td>...</td>\n      <td>0.261387</td>\n      <td>0.499989</td>\n      <td>0.095395</td>\n      <td>0.782473</td>\n      <td>-0.352024</td>\n      <td>0.710751</td>\n      <td>-0.044774</td>\n      <td>-0.033901</td>\n      <td>148.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>150166</th>\n      <td>92698.0</td>\n      <td>2.023521</td>\n      <td>0.214231</td>\n      <td>-1.464569</td>\n      <td>0.550398</td>\n      <td>0.440221</td>\n      <td>-0.621447</td>\n      <td>-0.020361</td>\n      <td>-0.170860</td>\n      <td>1.535655</td>\n      <td>...</td>\n      <td>-0.453848</td>\n      <td>-0.999219</td>\n      <td>0.365368</td>\n      <td>0.603461</td>\n      <td>-0.342527</td>\n      <td>0.104715</td>\n      <td>-0.094095</td>\n      <td>-0.045708</td>\n      <td>0.89</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>274927</th>\n      <td>166279.0</td>\n      <td>1.568033</td>\n      <td>-0.213043</td>\n      <td>-0.415472</td>\n      <td>4.250062</td>\n      <td>-0.135853</td>\n      <td>0.280004</td>\n      <td>0.126273</td>\n      <td>0.054357</td>\n      <td>-0.102412</td>\n      <td>...</td>\n      <td>-0.281574</td>\n      <td>-0.930429</td>\n      <td>0.189136</td>\n      <td>-0.087845</td>\n      <td>-0.244244</td>\n      <td>-0.269846</td>\n      <td>-0.042632</td>\n      <td>-0.020087</td>\n      <td>160.41</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11312</th>\n      <td>19692.0</td>\n      <td>1.165889</td>\n      <td>-0.390112</td>\n      <td>0.892399</td>\n      <td>-0.754121</td>\n      <td>-0.755755</td>\n      <td>0.205039</td>\n      <td>-0.849606</td>\n      <td>0.199267</td>\n      <td>2.888464</td>\n      <td>...</td>\n      <td>-0.100379</td>\n      <td>0.175587</td>\n      <td>-0.055054</td>\n      <td>-0.349088</td>\n      <td>0.408547</td>\n      <td>-0.693195</td>\n      <td>0.076051</td>\n      <td>0.013507</td>\n      <td>11.85</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6285</th>\n      <td>7413.0</td>\n      <td>-1.259891</td>\n      <td>-0.726624</td>\n      <td>2.327557</td>\n      <td>-2.315130</td>\n      <td>-1.715768</td>\n      <td>-0.258039</td>\n      <td>1.413266</td>\n      <td>-0.325328</td>\n      <td>2.575683</td>\n      <td>...</td>\n      <td>0.295721</td>\n      <td>0.648250</td>\n      <td>0.427393</td>\n      <td>0.331621</td>\n      <td>0.477176</td>\n      <td>-0.093332</td>\n      <td>-0.259823</td>\n      <td>-0.135088</td>\n      <td>370.39</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>236223</th>\n      <td>148717.0</td>\n      <td>2.338682</td>\n      <td>-1.334974</td>\n      <td>-1.378726</td>\n      <td>-1.908951</td>\n      <td>-0.550774</td>\n      <td>0.238072</td>\n      <td>-1.158720</td>\n      <td>-0.009707</td>\n      <td>-1.507455</td>\n      <td>...</td>\n      <td>-0.176079</td>\n      <td>0.000021</td>\n      <td>0.153596</td>\n      <td>-0.216030</td>\n      <td>-0.059567</td>\n      <td>-0.154875</td>\n      <td>0.006452</td>\n      <td>-0.064696</td>\n      <td>6.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>201201</th>\n      <td>133772.0</td>\n      <td>2.080428</td>\n      <td>-0.126444</td>\n      <td>-1.407207</td>\n      <td>0.351369</td>\n      <td>-0.115538</td>\n      <td>-1.324759</td>\n      <td>0.144910</td>\n      <td>-0.303543</td>\n      <td>0.857661</td>\n      <td>...</td>\n      <td>0.217186</td>\n      <td>0.712214</td>\n      <td>0.000297</td>\n      <td>-0.118319</td>\n      <td>0.231340</td>\n      <td>-0.096090</td>\n      <td>-0.030888</td>\n      <td>-0.063446</td>\n      <td>3.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>248330</th>\n      <td>153893.0</td>\n      <td>0.857433</td>\n      <td>0.679099</td>\n      <td>-3.725069</td>\n      <td>-1.234750</td>\n      <td>3.388773</td>\n      <td>3.137934</td>\n      <td>-0.348392</td>\n      <td>-2.192127</td>\n      <td>-0.789256</td>\n      <td>...</td>\n      <td>-0.844067</td>\n      <td>1.666051</td>\n      <td>0.062654</td>\n      <td>0.792094</td>\n      <td>-0.228489</td>\n      <td>0.487223</td>\n      <td>0.235530</td>\n      <td>0.416906</td>\n      <td>1.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284600</th>\n      <td>172590.0</td>\n      <td>2.058257</td>\n      <td>-1.714452</td>\n      <td>-1.002894</td>\n      <td>-1.557228</td>\n      <td>-1.314964</td>\n      <td>-0.494054</td>\n      <td>-0.997273</td>\n      <td>-0.166715</td>\n      <td>-1.482291</td>\n      <td>...</td>\n      <td>-0.084824</td>\n      <td>0.014041</td>\n      <td>0.103746</td>\n      <td>-0.342943</td>\n      <td>-0.246576</td>\n      <td>-0.207427</td>\n      <td>-0.008154</td>\n      <td>-0.041851</td>\n      <td>126.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>187686</th>\n      <td>127645.0</td>\n      <td>-0.011719</td>\n      <td>1.106394</td>\n      <td>-0.282688</td>\n      <td>0.661797</td>\n      <td>1.757857</td>\n      <td>-0.008939</td>\n      <td>1.482610</td>\n      <td>-0.352972</td>\n      <td>-0.451525</td>\n      <td>...</td>\n      <td>0.009578</td>\n      <td>0.483270</td>\n      <td>-0.382314</td>\n      <td>-0.013467</td>\n      <td>0.117852</td>\n      <td>-0.390229</td>\n      <td>0.268704</td>\n      <td>0.020517</td>\n      <td>5.15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>249194</th>\n      <td>154288.0</td>\n      <td>-0.513755</td>\n      <td>-0.200756</td>\n      <td>1.430028</td>\n      <td>-2.203717</td>\n      <td>0.316228</td>\n      <td>-0.211684</td>\n      <td>0.763676</td>\n      <td>-0.708394</td>\n      <td>-0.531281</td>\n      <td>...</td>\n      <td>0.091249</td>\n      <td>0.722135</td>\n      <td>-0.263764</td>\n      <td>-0.397016</td>\n      <td>-0.053290</td>\n      <td>-0.297371</td>\n      <td>-0.727034</td>\n      <td>-0.622340</td>\n      <td>17.95</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>224272</th>\n      <td>143719.0</td>\n      <td>-12.034428</td>\n      <td>-13.595066</td>\n      <td>-3.446061</td>\n      <td>1.526567</td>\n      <td>5.433066</td>\n      <td>-5.388983</td>\n      <td>-1.189171</td>\n      <td>0.376458</td>\n      <td>-1.870549</td>\n      <td>...</td>\n      <td>0.744190</td>\n      <td>0.543820</td>\n      <td>1.181284</td>\n      <td>0.941908</td>\n      <td>2.147286</td>\n      <td>0.290423</td>\n      <td>0.918294</td>\n      <td>-3.529290</td>\n      <td>8.25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32711</th>\n      <td>36934.0</td>\n      <td>1.037612</td>\n      <td>-0.092885</td>\n      <td>0.208346</td>\n      <td>1.253284</td>\n      <td>-0.063390</td>\n      <td>0.331403</td>\n      <td>-0.029316</td>\n      <td>0.189614</td>\n      <td>0.182889</td>\n      <td>...</td>\n      <td>-0.048541</td>\n      <td>-0.106970</td>\n      <td>-0.152946</td>\n      <td>-0.309133</td>\n      <td>0.626348</td>\n      <td>-0.312789</td>\n      <td>0.019332</td>\n      <td>0.010227</td>\n      <td>63.64</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9165</th>\n      <td>13083.0</td>\n      <td>-0.197607</td>\n      <td>1.035874</td>\n      <td>1.045698</td>\n      <td>-0.190877</td>\n      <td>0.912472</td>\n      <td>0.174510</td>\n      <td>0.664141</td>\n      <td>-0.115599</td>\n      <td>0.935436</td>\n      <td>...</td>\n      <td>-0.505791</td>\n      <td>-1.019145</td>\n      <td>-0.209408</td>\n      <td>-1.129660</td>\n      <td>-0.076380</td>\n      <td>0.071582</td>\n      <td>0.046155</td>\n      <td>-0.155653</td>\n      <td>5.49</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>141046</th>\n      <td>84096.0</td>\n      <td>1.240697</td>\n      <td>0.084088</td>\n      <td>0.387617</td>\n      <td>0.231309</td>\n      <td>-0.275212</td>\n      <td>-0.360848</td>\n      <td>-0.052933</td>\n      <td>-0.068952</td>\n      <td>0.017515</td>\n      <td>...</td>\n      <td>-0.204751</td>\n      <td>-0.450572</td>\n      <td>-0.002618</td>\n      <td>0.066256</td>\n      <td>0.378015</td>\n      <td>0.444868</td>\n      <td>-0.039896</td>\n      <td>-0.000662</td>\n      <td>4.00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25 rows × 31 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploring the Data Set**"
      ],
      "metadata": {
        "id": "smNHC3Xb0rrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "creditCard.describe().T"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T23:28:02.107698Z",
          "iopub.execute_input": "2024-12-10T23:28:02.107924Z",
          "iopub.status.idle": "2024-12-10T23:28:02.469172Z",
          "shell.execute_reply.started": "2024-12-10T23:28:02.107902Z",
          "shell.execute_reply": "2024-12-10T23:28:02.468383Z"
        },
        "id": "LilP1WIt0rrR",
        "outputId": "f2b7126f-1ea7-4dc8-df09-c5003877720d"
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "           count          mean           std         min           25%  \\\nTime    284807.0  9.481386e+04  47488.145955    0.000000  54201.500000   \nV1      284807.0  1.168375e-15      1.958696  -56.407510     -0.920373   \nV2      284807.0  3.416908e-16      1.651309  -72.715728     -0.598550   \nV3      284807.0 -1.379537e-15      1.516255  -48.325589     -0.890365   \nV4      284807.0  2.074095e-15      1.415869   -5.683171     -0.848640   \nV5      284807.0  9.604066e-16      1.380247 -113.743307     -0.691597   \nV6      284807.0  1.487313e-15      1.332271  -26.160506     -0.768296   \nV7      284807.0 -5.556467e-16      1.237094  -43.557242     -0.554076   \nV8      284807.0  1.213481e-16      1.194353  -73.216718     -0.208630   \nV9      284807.0 -2.406331e-15      1.098632  -13.434066     -0.643098   \nV10     284807.0  2.239053e-15      1.088850  -24.588262     -0.535426   \nV11     284807.0  1.673327e-15      1.020713   -4.797473     -0.762494   \nV12     284807.0 -1.247012e-15      0.999201  -18.683715     -0.405571   \nV13     284807.0  8.190001e-16      0.995274   -5.791881     -0.648539   \nV14     284807.0  1.207294e-15      0.958596  -19.214325     -0.425574   \nV15     284807.0  4.887456e-15      0.915316   -4.498945     -0.582884   \nV16     284807.0  1.437716e-15      0.876253  -14.129855     -0.468037   \nV17     284807.0 -3.772171e-16      0.849337  -25.162799     -0.483748   \nV18     284807.0  9.564149e-16      0.838176   -9.498746     -0.498850   \nV19     284807.0  1.039917e-15      0.814041   -7.213527     -0.456299   \nV20     284807.0  6.406204e-16      0.770925  -54.497720     -0.211721   \nV21     284807.0  1.654067e-16      0.734524  -34.830382     -0.228395   \nV22     284807.0 -3.568593e-16      0.725702  -10.933144     -0.542350   \nV23     284807.0  2.578648e-16      0.624460  -44.807735     -0.161846   \nV24     284807.0  4.473266e-15      0.605647   -2.836627     -0.354586   \nV25     284807.0  5.340915e-16      0.521278  -10.295397     -0.317145   \nV26     284807.0  1.683437e-15      0.482227   -2.604551     -0.326984   \nV27     284807.0 -3.660091e-16      0.403632  -22.565679     -0.070840   \nV28     284807.0 -1.227390e-16      0.330083  -15.430084     -0.052960   \nAmount  284807.0  8.834962e+01    250.120109    0.000000      5.600000   \nClass   284807.0  1.727486e-03      0.041527    0.000000      0.000000   \n\n                 50%            75%            max  \nTime    84692.000000  139320.500000  172792.000000  \nV1          0.018109       1.315642       2.454930  \nV2          0.065486       0.803724      22.057729  \nV3          0.179846       1.027196       9.382558  \nV4         -0.019847       0.743341      16.875344  \nV5         -0.054336       0.611926      34.801666  \nV6         -0.274187       0.398565      73.301626  \nV7          0.040103       0.570436     120.589494  \nV8          0.022358       0.327346      20.007208  \nV9         -0.051429       0.597139      15.594995  \nV10        -0.092917       0.453923      23.745136  \nV11        -0.032757       0.739593      12.018913  \nV12         0.140033       0.618238       7.848392  \nV13        -0.013568       0.662505       7.126883  \nV14         0.050601       0.493150      10.526766  \nV15         0.048072       0.648821       8.877742  \nV16         0.066413       0.523296      17.315112  \nV17        -0.065676       0.399675       9.253526  \nV18        -0.003636       0.500807       5.041069  \nV19         0.003735       0.458949       5.591971  \nV20        -0.062481       0.133041      39.420904  \nV21        -0.029450       0.186377      27.202839  \nV22         0.006782       0.528554      10.503090  \nV23        -0.011193       0.147642      22.528412  \nV24         0.040976       0.439527       4.584549  \nV25         0.016594       0.350716       7.519589  \nV26        -0.052139       0.240952       3.517346  \nV27         0.001342       0.091045      31.612198  \nV28         0.011244       0.078280      33.847808  \nAmount     22.000000      77.165000   25691.160000  \nClass       0.000000       0.000000       1.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Time</th>\n      <td>284807.0</td>\n      <td>9.481386e+04</td>\n      <td>47488.145955</td>\n      <td>0.000000</td>\n      <td>54201.500000</td>\n      <td>84692.000000</td>\n      <td>139320.500000</td>\n      <td>172792.000000</td>\n    </tr>\n    <tr>\n      <th>V1</th>\n      <td>284807.0</td>\n      <td>1.168375e-15</td>\n      <td>1.958696</td>\n      <td>-56.407510</td>\n      <td>-0.920373</td>\n      <td>0.018109</td>\n      <td>1.315642</td>\n      <td>2.454930</td>\n    </tr>\n    <tr>\n      <th>V2</th>\n      <td>284807.0</td>\n      <td>3.416908e-16</td>\n      <td>1.651309</td>\n      <td>-72.715728</td>\n      <td>-0.598550</td>\n      <td>0.065486</td>\n      <td>0.803724</td>\n      <td>22.057729</td>\n    </tr>\n    <tr>\n      <th>V3</th>\n      <td>284807.0</td>\n      <td>-1.379537e-15</td>\n      <td>1.516255</td>\n      <td>-48.325589</td>\n      <td>-0.890365</td>\n      <td>0.179846</td>\n      <td>1.027196</td>\n      <td>9.382558</td>\n    </tr>\n    <tr>\n      <th>V4</th>\n      <td>284807.0</td>\n      <td>2.074095e-15</td>\n      <td>1.415869</td>\n      <td>-5.683171</td>\n      <td>-0.848640</td>\n      <td>-0.019847</td>\n      <td>0.743341</td>\n      <td>16.875344</td>\n    </tr>\n    <tr>\n      <th>V5</th>\n      <td>284807.0</td>\n      <td>9.604066e-16</td>\n      <td>1.380247</td>\n      <td>-113.743307</td>\n      <td>-0.691597</td>\n      <td>-0.054336</td>\n      <td>0.611926</td>\n      <td>34.801666</td>\n    </tr>\n    <tr>\n      <th>V6</th>\n      <td>284807.0</td>\n      <td>1.487313e-15</td>\n      <td>1.332271</td>\n      <td>-26.160506</td>\n      <td>-0.768296</td>\n      <td>-0.274187</td>\n      <td>0.398565</td>\n      <td>73.301626</td>\n    </tr>\n    <tr>\n      <th>V7</th>\n      <td>284807.0</td>\n      <td>-5.556467e-16</td>\n      <td>1.237094</td>\n      <td>-43.557242</td>\n      <td>-0.554076</td>\n      <td>0.040103</td>\n      <td>0.570436</td>\n      <td>120.589494</td>\n    </tr>\n    <tr>\n      <th>V8</th>\n      <td>284807.0</td>\n      <td>1.213481e-16</td>\n      <td>1.194353</td>\n      <td>-73.216718</td>\n      <td>-0.208630</td>\n      <td>0.022358</td>\n      <td>0.327346</td>\n      <td>20.007208</td>\n    </tr>\n    <tr>\n      <th>V9</th>\n      <td>284807.0</td>\n      <td>-2.406331e-15</td>\n      <td>1.098632</td>\n      <td>-13.434066</td>\n      <td>-0.643098</td>\n      <td>-0.051429</td>\n      <td>0.597139</td>\n      <td>15.594995</td>\n    </tr>\n    <tr>\n      <th>V10</th>\n      <td>284807.0</td>\n      <td>2.239053e-15</td>\n      <td>1.088850</td>\n      <td>-24.588262</td>\n      <td>-0.535426</td>\n      <td>-0.092917</td>\n      <td>0.453923</td>\n      <td>23.745136</td>\n    </tr>\n    <tr>\n      <th>V11</th>\n      <td>284807.0</td>\n      <td>1.673327e-15</td>\n      <td>1.020713</td>\n      <td>-4.797473</td>\n      <td>-0.762494</td>\n      <td>-0.032757</td>\n      <td>0.739593</td>\n      <td>12.018913</td>\n    </tr>\n    <tr>\n      <th>V12</th>\n      <td>284807.0</td>\n      <td>-1.247012e-15</td>\n      <td>0.999201</td>\n      <td>-18.683715</td>\n      <td>-0.405571</td>\n      <td>0.140033</td>\n      <td>0.618238</td>\n      <td>7.848392</td>\n    </tr>\n    <tr>\n      <th>V13</th>\n      <td>284807.0</td>\n      <td>8.190001e-16</td>\n      <td>0.995274</td>\n      <td>-5.791881</td>\n      <td>-0.648539</td>\n      <td>-0.013568</td>\n      <td>0.662505</td>\n      <td>7.126883</td>\n    </tr>\n    <tr>\n      <th>V14</th>\n      <td>284807.0</td>\n      <td>1.207294e-15</td>\n      <td>0.958596</td>\n      <td>-19.214325</td>\n      <td>-0.425574</td>\n      <td>0.050601</td>\n      <td>0.493150</td>\n      <td>10.526766</td>\n    </tr>\n    <tr>\n      <th>V15</th>\n      <td>284807.0</td>\n      <td>4.887456e-15</td>\n      <td>0.915316</td>\n      <td>-4.498945</td>\n      <td>-0.582884</td>\n      <td>0.048072</td>\n      <td>0.648821</td>\n      <td>8.877742</td>\n    </tr>\n    <tr>\n      <th>V16</th>\n      <td>284807.0</td>\n      <td>1.437716e-15</td>\n      <td>0.876253</td>\n      <td>-14.129855</td>\n      <td>-0.468037</td>\n      <td>0.066413</td>\n      <td>0.523296</td>\n      <td>17.315112</td>\n    </tr>\n    <tr>\n      <th>V17</th>\n      <td>284807.0</td>\n      <td>-3.772171e-16</td>\n      <td>0.849337</td>\n      <td>-25.162799</td>\n      <td>-0.483748</td>\n      <td>-0.065676</td>\n      <td>0.399675</td>\n      <td>9.253526</td>\n    </tr>\n    <tr>\n      <th>V18</th>\n      <td>284807.0</td>\n      <td>9.564149e-16</td>\n      <td>0.838176</td>\n      <td>-9.498746</td>\n      <td>-0.498850</td>\n      <td>-0.003636</td>\n      <td>0.500807</td>\n      <td>5.041069</td>\n    </tr>\n    <tr>\n      <th>V19</th>\n      <td>284807.0</td>\n      <td>1.039917e-15</td>\n      <td>0.814041</td>\n      <td>-7.213527</td>\n      <td>-0.456299</td>\n      <td>0.003735</td>\n      <td>0.458949</td>\n      <td>5.591971</td>\n    </tr>\n    <tr>\n      <th>V20</th>\n      <td>284807.0</td>\n      <td>6.406204e-16</td>\n      <td>0.770925</td>\n      <td>-54.497720</td>\n      <td>-0.211721</td>\n      <td>-0.062481</td>\n      <td>0.133041</td>\n      <td>39.420904</td>\n    </tr>\n    <tr>\n      <th>V21</th>\n      <td>284807.0</td>\n      <td>1.654067e-16</td>\n      <td>0.734524</td>\n      <td>-34.830382</td>\n      <td>-0.228395</td>\n      <td>-0.029450</td>\n      <td>0.186377</td>\n      <td>27.202839</td>\n    </tr>\n    <tr>\n      <th>V22</th>\n      <td>284807.0</td>\n      <td>-3.568593e-16</td>\n      <td>0.725702</td>\n      <td>-10.933144</td>\n      <td>-0.542350</td>\n      <td>0.006782</td>\n      <td>0.528554</td>\n      <td>10.503090</td>\n    </tr>\n    <tr>\n      <th>V23</th>\n      <td>284807.0</td>\n      <td>2.578648e-16</td>\n      <td>0.624460</td>\n      <td>-44.807735</td>\n      <td>-0.161846</td>\n      <td>-0.011193</td>\n      <td>0.147642</td>\n      <td>22.528412</td>\n    </tr>\n    <tr>\n      <th>V24</th>\n      <td>284807.0</td>\n      <td>4.473266e-15</td>\n      <td>0.605647</td>\n      <td>-2.836627</td>\n      <td>-0.354586</td>\n      <td>0.040976</td>\n      <td>0.439527</td>\n      <td>4.584549</td>\n    </tr>\n    <tr>\n      <th>V25</th>\n      <td>284807.0</td>\n      <td>5.340915e-16</td>\n      <td>0.521278</td>\n      <td>-10.295397</td>\n      <td>-0.317145</td>\n      <td>0.016594</td>\n      <td>0.350716</td>\n      <td>7.519589</td>\n    </tr>\n    <tr>\n      <th>V26</th>\n      <td>284807.0</td>\n      <td>1.683437e-15</td>\n      <td>0.482227</td>\n      <td>-2.604551</td>\n      <td>-0.326984</td>\n      <td>-0.052139</td>\n      <td>0.240952</td>\n      <td>3.517346</td>\n    </tr>\n    <tr>\n      <th>V27</th>\n      <td>284807.0</td>\n      <td>-3.660091e-16</td>\n      <td>0.403632</td>\n      <td>-22.565679</td>\n      <td>-0.070840</td>\n      <td>0.001342</td>\n      <td>0.091045</td>\n      <td>31.612198</td>\n    </tr>\n    <tr>\n      <th>V28</th>\n      <td>284807.0</td>\n      <td>-1.227390e-16</td>\n      <td>0.330083</td>\n      <td>-15.430084</td>\n      <td>-0.052960</td>\n      <td>0.011244</td>\n      <td>0.078280</td>\n      <td>33.847808</td>\n    </tr>\n    <tr>\n      <th>Amount</th>\n      <td>284807.0</td>\n      <td>8.834962e+01</td>\n      <td>250.120109</td>\n      <td>0.000000</td>\n      <td>5.600000</td>\n      <td>22.000000</td>\n      <td>77.165000</td>\n      <td>25691.160000</td>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <td>284807.0</td>\n      <td>1.727486e-03</td>\n      <td>0.041527</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "creditCard.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T23:28:02.470480Z",
          "iopub.execute_input": "2024-12-10T23:28:02.470871Z",
          "iopub.status.idle": "2024-12-10T23:28:02.506816Z",
          "shell.execute_reply.started": "2024-12-10T23:28:02.470827Z",
          "shell.execute_reply": "2024-12-10T23:28:02.505992Z"
        },
        "id": "Gs4N2o9u0rrS",
        "outputId": "cbc2056c-2d7b-44ca-9913-77113be35257"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 284807 entries, 0 to 284806\nData columns (total 31 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   Time    284807 non-null  float64\n 1   V1      284807 non-null  float64\n 2   V2      284807 non-null  float64\n 3   V3      284807 non-null  float64\n 4   V4      284807 non-null  float64\n 5   V5      284807 non-null  float64\n 6   V6      284807 non-null  float64\n 7   V7      284807 non-null  float64\n 8   V8      284807 non-null  float64\n 9   V9      284807 non-null  float64\n 10  V10     284807 non-null  float64\n 11  V11     284807 non-null  float64\n 12  V12     284807 non-null  float64\n 13  V13     284807 non-null  float64\n 14  V14     284807 non-null  float64\n 15  V15     284807 non-null  float64\n 16  V16     284807 non-null  float64\n 17  V17     284807 non-null  float64\n 18  V18     284807 non-null  float64\n 19  V19     284807 non-null  float64\n 20  V20     284807 non-null  float64\n 21  V21     284807 non-null  float64\n 22  V22     284807 non-null  float64\n 23  V23     284807 non-null  float64\n 24  V24     284807 non-null  float64\n 25  V25     284807 non-null  float64\n 26  V26     284807 non-null  float64\n 27  V27     284807 non-null  float64\n 28  V28     284807 non-null  float64\n 29  Amount  284807 non-null  float64\n 30  Class   284807 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 67.4 MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The Data Set contain {creditCard.shape[0]} Rows & {creditCard.shape[1]} Columns\")\n",
        "print(f\"The Data Set contain {creditCard.duplicated().sum()} record duplicated\") # Flag Here\n",
        "print(f\"Number of Nulls in each features :\\n{creditCard.isna().sum()}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T23:28:02.507672Z",
          "iopub.execute_input": "2024-12-10T23:28:02.507904Z",
          "iopub.status.idle": "2024-12-10T23:28:03.025411Z",
          "shell.execute_reply.started": "2024-12-10T23:28:02.507881Z",
          "shell.execute_reply": "2024-12-10T23:28:03.024435Z"
        },
        "id": "82NU_rRl0rrT",
        "outputId": "bb432afd-11e6-41da-fa4d-446513616732"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "The Data Set contain 284807 Rows & 31 Columns\nThe Data Set contain 1081 record duplicated\nNumber of Nulls in each features :\nTime      0\nV1        0\nV2        0\nV3        0\nV4        0\nV5        0\nV6        0\nV7        0\nV8        0\nV9        0\nV10       0\nV11       0\nV12       0\nV13       0\nV14       0\nV15       0\nV16       0\nV17       0\nV18       0\nV19       0\nV20       0\nV21       0\nV22       0\nV23       0\nV24       0\nV25       0\nV26       0\nV27       0\nV28       0\nAmount    0\nClass     0\ndtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imbalanced Features Resolving**"
      ],
      "metadata": {
        "id": "yegt-eLy0rrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = creditCard.drop('Class', axis=1), creditCard['Class']\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_smote, y_resampled_smote = smote.fit_resample(X, y)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split( X_resampled_smote, y_resampled_smote, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "xxRdfAsr0rrV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modeling Our Data**"
      ],
      "metadata": {
        "id": "LEPyc2OC0rrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelAdam = Sequential()\n",
        "modelAdam.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
        "modelAdam.add(Dense(256, activation='relu'))\n",
        "modelAdam.add(Dense(128, activation='relu'))\n",
        "modelAdam.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
        "\n",
        "modelAdam.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "traceEpochs = Trace_back_epochs()\n",
        "\n",
        "modelAdam.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[Trace_back_epochs]\n",
        ")\n",
        "\n",
        "traceEpochs.export_to_file(\"Tracing Measures/Trial_1.txt\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T23:28:11.952404Z",
          "iopub.execute_input": "2024-12-10T23:28:11.952742Z",
          "iopub.status.idle": "2024-12-10T23:48:00.248013Z",
          "shell.execute_reply.started": "2024-12-10T23:28:11.952712Z",
          "shell.execute_reply": "2024-12-10T23:48:00.247377Z"
        },
        "id": "bm5TOaXo0rrW",
        "outputId": "c0dda7e1-de05-4285-a1f8-3fa19e95f979"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1/50\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733873295.479291      82 service.cc:145] XLA service 0x7c6e68007100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1733873295.479348      82 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1733873295.479352      82 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u001b[1m  113/14216\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.8910 - loss: 0.2589 ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "I0000 00:00:1733873297.003576      82 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0334 - val_accuracy: 0.9981 - val_loss: 0.0092\nEpoch 2/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0058 - val_accuracy: 0.9992 - val_loss: 0.0039\nEpoch 3/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0041 - val_accuracy: 0.9992 - val_loss: 0.0038\nEpoch 4/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.9990 - val_loss: 0.0067\nEpoch 5/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.9994 - val_loss: 0.0031\nEpoch 6/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9996 - val_loss: 0.0017\nEpoch 7/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9997 - val_loss: 0.0020\nEpoch 8/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9997 - val_loss: 0.0018\nEpoch 9/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9997 - val_loss: 0.0016\nEpoch 10/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9998 - val_loss: 0.0013\nEpoch 11/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9997 - val_loss: 0.0028\nEpoch 12/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9996 - val_loss: 0.0032\nEpoch 13/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9995 - val_loss: 0.0027\nEpoch 14/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9998 - val_loss: 0.0016\nEpoch 15/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9985 - val_loss: 0.0099\nEpoch 16/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9996 - val_loss: 0.0033\nEpoch 17/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9998 - val_loss: 0.0021\nEpoch 18/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9999 - val_loss: 0.0016\nEpoch 19/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0022 - val_accuracy: 0.9996 - val_loss: 0.0014\nEpoch 20/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9992 - val_loss: 0.0069\nEpoch 21/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9998 - val_loss: 0.0019\nEpoch 22/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9998 - val_loss: 0.0019\nEpoch 23/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0022 - val_accuracy: 0.9985 - val_loss: 0.0071\nEpoch 24/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9998 - val_loss: 0.0021\nEpoch 25/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9998 - val_loss: 0.0018\nEpoch 26/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9999 - val_loss: 0.0012\nEpoch 27/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 9.2866e-04 - val_accuracy: 0.9987 - val_loss: 0.0138\nEpoch 28/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 0.9998 - val_loss: 0.0015\nEpoch 29/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 7.6678e-04 - val_accuracy: 0.9997 - val_loss: 0.0025\nEpoch 30/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9995 - val_loss: 0.0025\nEpoch 31/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9996 - val_loss: 0.0037\nEpoch 32/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9997 - val_loss: 0.0027\nEpoch 33/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9999 - val_loss: 0.0016\nEpoch 34/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0049 - val_accuracy: 0.9999 - val_loss: 9.0907e-04\nEpoch 35/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 7.6885e-04 - val_accuracy: 0.9999 - val_loss: 0.0011\nEpoch 36/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0032 - val_accuracy: 0.9998 - val_loss: 0.0013\nEpoch 37/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 9.5048e-04 - val_accuracy: 0.9998 - val_loss: 0.0031\nEpoch 38/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 6.6037e-04 - val_accuracy: 0.9998 - val_loss: 0.0021\nEpoch 39/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 7.5979e-04 - val_accuracy: 0.9999 - val_loss: 0.0026\nEpoch 40/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9997 - val_loss: 0.0030\nEpoch 41/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9999 - val_loss: 8.4911e-04\nEpoch 42/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9998 - val_loss: 0.0020\nEpoch 43/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 9.8132e-04 - val_accuracy: 0.9997 - val_loss: 0.0037\nEpoch 44/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9998 - val_loss: 0.0018\nEpoch 45/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9997 - val_loss: 0.0031\nEpoch 46/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 9.2862e-04 - val_accuracy: 0.9999 - val_loss: 0.0016\nEpoch 47/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.9999 - val_loss: 0.0041\nEpoch 48/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 0.9998 - val_loss: 0.0025\nEpoch 49/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 5.6197e-04 - val_accuracy: 0.9997 - val_loss: 0.0016\nEpoch 50/50\n\u001b[1m14216/14216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 8.8122e-04 - val_accuracy: 0.9999 - val_loss: 0.0012\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"Trial 1.txt\", \"w\") as fp:\n",
        "    fp.writelines('%s\\n' % value for value in plotly_callback.val_loss)\n",
        "    fp.write(\"\\nValidation Accuracy:\\n\")\n",
        "    fp.writelines('%s\\n' % value for value in plotly_callback.val_accuracy)"
      ],
      "metadata": {
        "id": "vsaItWed1HUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "existing_files = [f for f in os.listdir(\"/Phase_2/Predictions\") if f.endswith('.csv')]\n",
        "testFile = pd.read_csv(\"/kaggle/input/classification-test-file/Classification_Test_file.csv\")\n",
        "testFile_scaled = scaler.transform(testFile)\n",
        "y_pred_multiclassAdam = np.argmax(modelAdam.predict(testFile_scaled), axis=1)\n",
        "dictt = {\n",
        "    \"ID\": [i for i in range(len(testFile))],\n",
        "    \"Class\": y_pred_multiclassAdam\n",
        "}\n",
        "df = pd.DataFrame(dictt)\n",
        "output_file_path = os.path.join(predictions_dir, f\"Task-2 Trial ({len(existing_files) + 1 }).csv\")\n",
        "df.to_csv(output_file_path, index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AWEBr74k0rrW"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}